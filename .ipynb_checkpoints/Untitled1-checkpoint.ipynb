{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46e645ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Class: Fake\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('fake_news_model1.h5')\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer1.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Create a PorterStemmer instance\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Define the sequence length for padding\n",
    "sent_length = 5000  # Replace with the actual value you used for padding during training\n",
    "\n",
    "# User's input\n",
    "user_input = \"drunk brag trump staffer start russian collus investigationhous intellig committe chairman devin nune go bad day assumpt like mani us christoph steeledossi prompt russia investig lash depart justic fbi order protect trump happen dossier start investig accord document obtain new york timesform trump campaign advis georg papadopoulo drunk wine bar reveal knowledg russian opposit research hillari clintonon top papadopoulo covfef boy trump administr alleg much larger role none damn drunken fool wine bar coffe boy help arrang new york meet trump presid abdel fattah elsisi egypt two month elect known former aid set meet world leader trump team trump ran mere coffe boyin may papadopoulo reveal australian diplomat alexand downer russian offici shop around possibl dirt thendemocrat presidenti nomine hillari clinton exactli much mr papadopoulo said night kensington wine room australian alexand downer unclear report state two month later leak democrat email began appear onlin australian offici pass inform mr papadopoulo american counterpart accord four current former american foreign offici direct knowledg australian role papadopoulo plead guilti lie fbi cooper wit special counsel robert mueller teamthi presid badli script realiti tv showphoto win mcnameegetti imag\"\n",
    "\n",
    "# Preprocess the user input\n",
    "def preprocess_input(text):\n",
    "    # Apply the same preprocessing steps as in your training code\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if not word in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "preprocessed_input = preprocess_input(user_input)\n",
    "\n",
    "# Vectorize the preprocessed input\n",
    "vectorized_input = tfidf_vectorizer.transform([preprocessed_input])\n",
    "\n",
    "# Convert the sparse matrix to an array\n",
    "vectorized_input_array = vectorized_input.toarray()\n",
    "\n",
    "# Pad the vectorized input\n",
    "padded_input = pad_sequences(vectorized_input_array, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(padded_input)\n",
    "\n",
    "# Convert prediction to class label\n",
    "predicted_class = \"Fake\" if prediction[0][0] < 0.5 else \"True\"\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95173dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Class: Fake\n",
      "Probability of Fake: 0.3063\n",
      "Probability of True: 0.6937\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('fake_news_model.h5')\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Create a PorterStemmer instance\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Define the sequence length for padding\n",
    "sent_length = 5000  # Replace with the actual value you used for padding during training\n",
    "\n",
    "# User's input\n",
    "user_input = \"drunk brag trump staffer start russian collus investigationhous intellig committe chairman devin nune go bad day assumpt like mani us christoph steeledossi prompt russia investig lash depart justic fbi order protect trump happen dossier start investig accord document obtain new york timesform trump campaign advis georg papadopoulo drunk wine bar reveal knowledg russian opposit research hillari clintonon top papadopoulo covfef boy trump administr alleg much larger role none damn drunken fool wine bar coffe boy help arrang new york meet trump presid abdel fattah elsisi egypt two month elect known former aid set meet world leader trump team trump ran mere coffe boyin may papadopoulo reveal australian diplomat alexand downer russian offici shop around possibl dirt thendemocrat presidenti nomine hillari clinton exactli much mr papadopoulo said night kensington wine room australian alexand downer unclear report state two month later leak democrat email began appear onlin australian offici pass inform mr papadopoulo american counterpart accord four current former american foreign offici direct knowledg australian role papadopoulo plead guilti lie fbi cooper wit special counsel robert mueller teamthi presid badli script realiti tv showphoto win mcnameegetti imag\"\n",
    "\n",
    "\n",
    "# Preprocess the user input\n",
    "def preprocess_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if not word in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "preprocessed_input = preprocess_input(user_input)\n",
    "\n",
    "# Vectorize the preprocessed input\n",
    "vectorized_input = tfidf_vectorizer.transform([preprocessed_input])\n",
    "\n",
    "# Convert the sparse matrix to an array\n",
    "vectorized_input_array = vectorized_input.toarray()\n",
    "\n",
    "# Pad the vectorized input\n",
    "padded_input = pad_sequences(vectorized_input_array, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Make prediction\n",
    "proba = model.predict(padded_input)\n",
    "\n",
    "# Convert prediction probabilities to class labels\n",
    "predicted_class = \"Fake\" if proba[0][0] < 0.5 else \"True\"\n",
    "other_class = \"True\" if predicted_class == \"Fake\" else \"Fake\"\n",
    "\n",
    "# Print prediction probabilities for each class\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probability of {predicted_class}: {proba[0][0]:.4f}\")\n",
    "print(f\"Probability of {other_class}: {1 - proba[0][0]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7c0a75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Class: Fake\n",
      "Probability of Predicted Class: 0.8331\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('fake_news_model1.h5')\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer1.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Create a PorterStemmer instance\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# User's input\n",
    "user_input = \"Your input text goes here.\"\n",
    "\n",
    "# Preprocess the user input\n",
    "def preprocess_input(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.split()\n",
    "    text = [ps.stem(word) for word in text if not word in stop_words]\n",
    "    text = ' '.join(text)\n",
    "    return text\n",
    "\n",
    "preprocessed_input = preprocess_input(user_input)\n",
    "\n",
    "# Vectorize the preprocessed input\n",
    "vectorized_input = tfidf_vectorizer.transform([preprocessed_input])\n",
    "\n",
    "# Convert the sparse matrix to an array\n",
    "vectorized_input_array = vectorized_input.toarray()\n",
    "\n",
    "# Pad the vectorized input\n",
    "sent_length = 5000  # Replace with the actual value you used for padding during training\n",
    "padded_input = pad_sequences(vectorized_input_array, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Make prediction\n",
    "prediction = model.predict(padded_input)\n",
    "\n",
    "# Print prediction result\n",
    "predicted_class = \"Fake\" if prediction[0][0] < 0.5 else \"True\"\n",
    "predicted_proba = prediction[0][0] if predicted_class == \"True\" else 1 - prediction[0][0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probability of Predicted Class: {predicted_proba:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a30d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a news text: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m stemmed_input \u001b[38;5;241m=\u001b[39m [ps\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m user_input\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[0;32m      7\u001b[0m input_corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_input)\n\u001b[1;32m----> 8\u001b[0m input_onehot_repr \u001b[38;5;241m=\u001b[39m [\u001b[43mone_hot\u001b[49m(input_corpus, voc_size)]\n\u001b[0;32m      9\u001b[0m input_padded \u001b[38;5;241m=\u001b[39m pad_sequences(input_onehot_repr, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m, maxlen\u001b[38;5;241m=\u001b[39msent_length)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Predict using the trained model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "# Take user input\n",
    "user_input = input(\"Enter a news text: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "# cleaned_input = review_cleaning(user_input)\n",
    "stemmed_input = [ps.stem(word) for word in user_input.split() if not word in stop_words]\n",
    "input_corpus = ' '.join(stemmed_input)\n",
    "input_onehot_repr = [one_hot(input_corpus, voc_size)]\n",
    "input_padded = pad_sequences(input_onehot_repr, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(input_padded)\n",
    "\n",
    "# Print prediction result\n",
    "predicted_class = \"True\" if prediction[0][0] < 0.5 else \"Fake\"\n",
    "predicted_proba = prediction[0][0] if predicted_class == \"False\" else 1 - prediction[0][0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probability of Predicted Class: {predicted_proba:.4f}\")\n",
    "\n",
    "# Print the result\n",
    "if prediction[0][0] < 0.5:\n",
    "    print(\"The input news is classified as True.\")\n",
    "else:\n",
    "    print(\"The input news is classified as False.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb84e729",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c90c6208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('fake_news_model1.h5')\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer1.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Create a PorterStemmer instance\n",
    "ps = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e57fdf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a news text: h\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'one_hot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 41\u001b[0m\n\u001b[0;32m     39\u001b[0m stemmed_input \u001b[38;5;241m=\u001b[39m [ps\u001b[38;5;241m.\u001b[39mstem(word) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m cleaned_input\u001b[38;5;241m.\u001b[39msplit() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m stop_words]\n\u001b[0;32m     40\u001b[0m input_corpus \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(stemmed_input)\n\u001b[1;32m---> 41\u001b[0m input_onehot_repr \u001b[38;5;241m=\u001b[39m [\u001b[43mone_hot\u001b[49m(input_corpus, voc_size)]  \u001b[38;5;66;03m# Define 'one_hot' function here\u001b[39;00m\n\u001b[0;32m     42\u001b[0m input_padded \u001b[38;5;241m=\u001b[39m pad_sequences(input_onehot_repr, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre\u001b[39m\u001b[38;5;124m'\u001b[39m, maxlen\u001b[38;5;241m=\u001b[39msent_length)\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Predict using the trained model\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'one_hot' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('fake_news_model1.h5')\n",
    "\n",
    "# Load the TF-IDF vectorizer\n",
    "with open('tfidf_vectorizer1.pkl', 'rb') as f:\n",
    "    tfidf_vectorizer = pickle.load(f)\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Create a PorterStemmer instance\n",
    "ps = PorterStemmer()\n",
    "\n",
    "# Define the review_cleaning function\n",
    "def review_cleaning(text):\n",
    "    '''Make text lowercase, remove text in square brackets, remove links, remove punctuation,\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "# Take user input\n",
    "user_input = input(\"Enter a news text: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "cleaned_input = review_cleaning(user_input)\n",
    "stemmed_input = [ps.stem(word) for word in cleaned_input.split() if not word in stop_words]\n",
    "input_corpus = ' '.join(stemmed_input)\n",
    "input_onehot_repr = [one_hot(input_corpus, voc_size)]  # Define 'one_hot' function here\n",
    "input_padded = pad_sequences(input_onehot_repr, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(input_padded)\n",
    "\n",
    "# Print prediction result\n",
    "predicted_class = \"True\" if prediction[0][0] < 0.5 else \"Fake\"\n",
    "predicted_proba = prediction[0][0] if predicted_class == \"Fake\" else 1 - prediction[0][0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probability of Predicted Class: {predicted_proba:.4f}\")\n",
    "\n",
    "# Print the result\n",
    "if predicted_class == \"True\":\n",
    "    print(\"The input news is classified as True.\")\n",
    "else:\n",
    "    print(\"The input news is classified as Fake.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1bd54740",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m voc_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#One hot encoding \u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m onehot_repr\u001b[38;5;241m=\u001b[39m[one_hot(words,voc_size)\u001b[38;5;28;01mfor\u001b[39;00m words \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcorpus\u001b[49m] \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Setting sentence length\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sent_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5000\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "#Setting up vocabulary size\n",
    "voc_size=10000\n",
    "\n",
    "#One hot encoding \n",
    "onehot_repr=[one_hot(words,voc_size)for words in corpus] \n",
    "\n",
    "#Setting sentence length\n",
    "sent_length=5000\n",
    "\n",
    "#Padding the sentences\n",
    "embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "print(embedded_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8951528c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ce5757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea740a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, render_template, request\n",
    "import numpy as np\n",
    "import joblib\n",
    "import string\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f89f1a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a news text: d\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Class: True\n",
      "Probability of Predicted Class: 0.6937\n",
      "The input news is classified as True.\n"
     ]
    }
   ],
   "source": [
    "model = load_model('fake_news_model.h5')\n",
    "\n",
    "voc_size = 10000\n",
    "sent_length=5000\n",
    "def review_cleaning(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "#Performing stemming on the review dataframe\n",
    "\n",
    "# Take user input\n",
    "user_input = input(\"Enter a news text: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "cleaned_input = review_cleaning(user_input)\n",
    "stemmed_input = [ps.stem(word) for word in cleaned_input.split() if not word in stop_words]\n",
    "input_corpus = ' '.join(stemmed_input)\n",
    "input_onehot_repr = [one_hot(input_corpus, voc_size)]\n",
    "input_padded = pad_sequences(input_onehot_repr, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(input_padded)\n",
    "\n",
    "# Print prediction result\n",
    "predicted_class = \"True\" if prediction[0][0] < 0.8 else \"Fake\"\n",
    "predicted_proba = prediction[0][0] if predicted_class == \"False\" else 1 - prediction[0][0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probability of Predicted Class: {predicted_proba:.4f}\")\n",
    "\n",
    "# Print the result\n",
    "if prediction[0][0] < 0.8:\n",
    "    print(\"The input news is classified as True.\")\n",
    "else:\n",
    "    print(\"The input news is classified as False.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab676e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a news text: John Podesta is the guardian of the Clintons just like Valerie Jarrett was for the Obamas.  He was instrumental during the 2016 election as the Clinton campaign chair and was exposed when the Wikileaks hack happened. He was just interviewed by the House Intel Committee regarding the Russia scam and was asked about it in the heated debate below:https://www.youtube.com/watch?v=z9U5zxVyTqAJohn Podesta is not just the former chairman of the Hillary Clinton s presidential campaign, but also a central figure in the ongoing narrative of Russian meddling in the US election of 2016. His hacked emails were at the heart of what some have called a coordinated news campaign led by Wikileaks, and so he met with the House Intelligence panel yesterday behind closed doors.This morning he appeared on Fox Business to discuss the Russian interference, allegations of collusion with Trump campaign and more with host Maria Bartiromo in what became a testy debate that perfectly exemplifies the divided positions that so many Americans hold right now.Bartiromo showed skepticism over the Russia claims rightfully so!. And there may be no other individual that best embodies the Clinton s web of influence   for good and bad   than Mr. Podesta. He s the definition of a weasel.Bartiromo aggressively attacked Podesta and Democrats for what she said were deeper ties with Russia, specifically asking about Podesta s investment portfolio:THIS IS JUST ONE EXAMPLE OF A  DEEP TIE  TO RUSSIA:Russia gave John Podesta 35 millions dollars (1 billion rubles) while he advised Hillary Clinton and Barack Obama.Russia gave John Podesta 35 millions dollars (1 billion rubles) while he advised Hillary Clinton and Barack Obama. pic.twitter.com/cf042XZLeU  Based Vet   (@BasedVet) March 28, 2017 Get your facts straight,  the former Clinton campaign chair shot back, before dismissing the FBN hosts claims as coming from a dubious source  like InfoWars. It went downhill from there.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Class: True\n",
      "Probability of Predicted Class: 0.7747\n",
      "Probability of Predicted Class: 0.2253\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import one_hot\n",
    "\n",
    "# Load the model\n",
    "model = load_model('fake_news_model.h5')\n",
    "\n",
    "# Initialize nltk components\n",
    "ps = PorterStemmer()\n",
    "\n",
    "voc_size = 10000\n",
    "sent_length = 5000\n",
    "\n",
    "def review_cleaning(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Take user input\n",
    "user_input = input(\"Enter a news text: \")\n",
    "\n",
    "# Preprocess the user input\n",
    "cleaned_input = review_cleaning(user_input)\n",
    "stemmed_input = [ps.stem(word) for word in cleaned_input.split() if not word in stop_words]\n",
    "input_corpus = ' '.join(stemmed_input)\n",
    "input_onehot_repr = [one_hot(input_corpus, voc_size)]\n",
    "input_padded = pad_sequences(input_onehot_repr, padding='pre', maxlen=sent_length)\n",
    "\n",
    "# Predict using the trained model\n",
    "prediction = model.predict(input_padded)\n",
    "\n",
    "# Print prediction result\n",
    "predicted_class = \"Fake\" if prediction[0][0] >= 0.3 else \"True\"\n",
    "# predicted_proba = prediction[0][0] if predicted_class == \"Fake\" else 1 - prediction[0][0]\n",
    "pp = prediction[0][0]\n",
    "\n",
    "print(f\"Predicted Class: {predicted_class}\")\n",
    "print(f\"Probability of Predicted Class: {predicted_proba:.4f}\")\n",
    "print(f\"Probability of Predicted Class: {pp:.4f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b5fed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionnn = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "daf25e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21217525"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionnn [0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cdeaab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
